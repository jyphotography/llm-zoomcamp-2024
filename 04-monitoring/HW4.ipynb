{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c34f7a-2189-468b-9fe3-9179c553bd81",
   "metadata": {},
   "source": [
    "## Homework: Evaluation and Monitoring\n",
    "In this homework, we'll evaluate the quality of our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a713e6a-319c-45dc-917e-aa3803232bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa48c5d-a522-47b3-9e30-5a580209568f",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "Let's start by getting the dataset. We will use the data we generated in the module.\n",
    "\n",
    "In particular, we'll evaluate the quality of our RAG system with gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead95175-1186-4c91-9e3e-2887935df005",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f23ba15-e26e-415e-aeeb-eef3efd30d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bf3500-4fef-4a17-88a7-67de3d05f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469f153-933f-44b7-a74d-6313ace3b43f",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "Now, get the embeddings model multi-qa-mpnet-base-dot-v1 from the Sentence Transformer library\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39117d1a-4f62-422c-851e-d28c1e11596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec106a7e-523f-4fcf-9a21-ba1089072ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23cd37-3665-42ef-b389-37ab9bb91ec4",
   "metadata": {},
   "source": [
    "Create the embeddings for the first LLM answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dd5f29a-4c5e-40f6-9549-9160c43e8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e6c7c1-2e44-4cd5-ba74-a7bc35d4f2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252a2fad-6408-41ab-9264-4a653d54d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61482b98-2179-4376-ac8e-b1632eeec3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244655"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0027b-6e28-4a8a-bd0f-dba91b9201bd",
   "metadata": {},
   "source": [
    "## Q2. Computing the dot product\n",
    "Now for each answer pair, let's create embeddings and compute dot product between them\n",
    "\n",
    "We will put the results (scores) into the evaluations list\n",
    "\n",
    "What's the 75% percentile of the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6dc3992-beee-40c5-a603-8adf6df39948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.515987"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_orig = df['answer_orig'][0]\n",
    "answer_llm = df['answer_llm'][0]\n",
    "\n",
    "v_orig = embedding_model.encode(answer_orig)\n",
    "v_llm = embedding_model.encode(answer_llm)\n",
    "\n",
    "v_orig.dot(v_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e608b079-6d87-4d39-9180-17e18f557d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['orig_vector'] = df['answer_orig'].apply(lambda x: embedding_model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1372efbb-1566-472d-a109-64bd97e0f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llm_vector'] = df['answer_llm'].apply(lambda x: embedding_model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f38456-a308-4373-bf8c-df1331fdb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dot_product'] = df.apply(lambda row: row['orig_vector'].dot(row['llm_vector']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abcd96ef-0c27-4e36-ad74-17708461853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.67430877685547"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dot_product'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1545a862-1b66-4c65-bc97-ab476c0c35a8",
   "metadata": {},
   "source": [
    "## Q3. Computing the cosine\n",
    "From Q2, we can see that the results are not within the [0, 1] range. It's because the vectors coming from this model are not normalized.\n",
    "\n",
    "So we need to normalize them.\n",
    "\n",
    "To do it, we\n",
    "\n",
    "* Compute the norm of a vector\n",
    "* Divide each element by this norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d163cf03-7a0a-4f9f-8141-89c3a040ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93e85338-aac0-4d77-b5de-e466f0fdf09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['orig_vector_norm'] = df['orig_vector'].apply(normalize_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21d07bb5-8db2-4c72-988e-174b2b77d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llm_vector_norm'] = df['llm_vector'].apply(normalize_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac0b2cc3-fe62-4552-9b71-f750b1c4bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dot_product_norm'] = df.apply(lambda row: row['orig_vector_norm'].dot(row['llm_vector_norm']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc9b9fb-12d5-4eb6-afdc-ce38c9067628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362348973751068"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dot_product_norm'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555c804-10b6-4289-ae8c-476902553449",
   "metadata": {},
   "source": [
    "## Q4. Rouge\n",
    "Now we will explore an alternative metric - the ROUGE score.\n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3efe429-30b8-4f80-8058-b48bbba8c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a38c71-5981-44ea-8044-1658c08946af",
   "metadata": {},
   "source": [
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (doc_id=5170565b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b53bafeb-5645-4a22-bb43-d99557ae40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dfb2a84-c332-48eb-b63a-c93ea1a6f264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_llm          Yes, all sessions are recorded, so if you miss...\n",
       "answer_orig         Everything is recorded, so you won’t miss anyt...\n",
       "document                                                     5170565b\n",
       "question                         Are sessions recorded if I miss one?\n",
       "course                                      machine-learning-zoomcamp\n",
       "orig_vector         [-0.22097382, -0.07662514, -0.19240223, -0.038...\n",
       "llm_vector          [-0.10797262, -0.07068468, -0.091208436, 0.092...\n",
       "dot_product                                                 32.344711\n",
       "orig_vector_norm    [-0.03465839, -0.012018184, -0.030177113, -0.0...\n",
       "llm_vector_norm     [-0.016557612, -0.010839502, -0.013986822, 0.0...\n",
       "dot_product_norm                                             0.777956\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = df.iloc[10]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5405733-df71-4d04-b9ef-5bde5d00cf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8792b3-4aff-4509-98dd-32d63b92ed87",
   "metadata": {},
   "source": [
    "What's the F score for rouge-1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4ccfed0-a4e5-4003-b1be-9b2c6c726495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086505e7-fc32-43be-af68-431fe434b739",
   "metadata": {},
   "source": [
    "## Q5. Average rouge score\n",
    "Let's compute the average F-score between rouge-1, rouge-2 and rouge-l for the same record from Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2073fa37-f6aa-40a0-b14b-34e684278bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scores = []\n",
    "for key in scores:\n",
    "    f_scores.append(scores[key]['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9f06130-845e-4308-b36e-2c9af51428c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_f_scores = sum(f_scores) /len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba950507-9bc3-488e-a3ec-56e2d849ba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_f_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf308b8-61df-4b8d-aaea-192c214609f7",
   "metadata": {},
   "source": [
    "## Q6. Average rouge score for all the data points\n",
    "Now let's compute the score for all the records and create a dataframe from them.\n",
    "\n",
    "What's the average rouge_2 across all the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c25753a7-b300-445a-b60a-c8eb3f9c1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rouge_2_f'] = df.apply(lambda row: rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]['rouge-2']['f'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0879fbd-73b0-48ac-bc8f-409a85505eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['rouge_2_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f2e55-b3ec-4684-b643-200794849b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c8b6f-cfd9-4236-ab48-64ecd3b8a6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
