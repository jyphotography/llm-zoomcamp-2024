{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a0b8fd-a442-47a3-990d-3a70969b0ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-30 15:13:52--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-30 15:13:52 (31.6 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b1095a-c8be-4945-b375-7ac6a0617d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f4a8ebe6470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80912d7-fd61-4688-9fa3-ef65e7388d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "415c7a21-d5bc-4612-b30a-0edc9783ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5269d3ee-2707-4dd9-81fc-bc8689b6c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22493ba-a72b-469c-ae0d-5cba2af5bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7194df4b-659a-4bd2-b260-ee3ac878131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This statement, \"This is a test,\" is typically used to indicate the initial testing phase of software or any system. It serves multiple purposes:\\n\\n1. **Identification**: Early in development, it\\'s crucial for developers and quality assurance (QA) engineers to identify potential issues, bugs, or areas that require improvement within a system. By running tests during this phase, the team can ensure smooth progression into subsequent stages of development.\\n\\n2. **Functionality Check**: The statement helps in verifying whether fundamental functionalities are working as intended before more complex features and systems are implemented. This could range from simple unit tests to checks for integration among components.\\n\\n3. **Documentation and Communication**: It\\'s a standardized phrase used globally, making it easy for anyone involved in the project, regardless of their role, to recognize that a test is being conducted. This helps in maintaining clear communication across teams and documentation purposes.\\n\\n4. **Safety Measures**: In some environments (e.g., system backups, safety protocols), tests might be run under specific conditions or scenarios to ensure systems are functioning correctly even before fully deployed changes take effect. The phrase \"This is a test\" signals that operations in this context should not impact critical services or user data due to its controlled nature.\\n\\n5. **Mock Environments**: Before deploying any live application, especially one with significant functionality (such as banking apps), developers might first conduct tests within mocked-up environments to ensure the logic and workflows function correctly under different scenarios without affecting real users or data.\\n\\nIn summary, using \"This is a test\" serves not only as an instruction for system verification but also plays a critical role in ensuring quality control during development processes. It\\'s essential for facilitating clear communication across teams and helps maintain the integrity of live systems through controlled testing phases.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('write that this is a test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3bf8727-ee74-41c5-a1a9-a5f9858ba645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This statement, \"This is a test,\" is typically used to indicate the initial testing phase of software or any system. It serves multiple purposes:\n",
      "\n",
      "1. **Identification**: Early in development, it's crucial for developers and quality assurance (QA) engineers to identify potential issues, bugs, or areas that require improvement within a system. By running tests during this phase, the team can ensure smooth progression into subsequent stages of development.\n",
      "\n",
      "2. **Functionality Check**: The statement helps in verifying whether fundamental functionalities are working as intended before more complex features and systems are implemented. This could range from simple unit tests to checks for integration among components.\n",
      "\n",
      "3. **Documentation and Communication**: It's a standardized phrase used globally, making it easy for anyone involved in the project, regardless of their role, to recognize that a test is being conducted. This helps in maintaining clear communication across teams and documentation purposes.\n",
      "\n",
      "4. **Safety Measures**: In some environments (e.g., system backups, safety protocols), tests might be run under specific conditions or scenarios to ensure systems are functioning correctly even before fully deployed changes take effect. The phrase \"This is a test\" signals that operations in this context should not impact critical services or user data due to its controlled nature.\n",
      "\n",
      "5. **Mock Environments**: Before deploying any live application, especially one with significant functionality (such as banking apps), developers might first conduct tests within mocked-up environments to ensure the logic and workflows function correctly under different scenarios without affecting real users or data.\n",
      "\n",
      "In summary, using \"This is a test\" serves not only as an instruction for system verification but also plays a critical role in ensuring quality control during development processes. It's essential for facilitating clear communication across teams and helps maintain the integrity of live systems through controlled testing phases.\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0520e0-bdc3-41e6-912a-ce78db32e07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a013338-6fca-44be-bf5e-e70597e03a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
