{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9af1d90-1fd1-4539-803a-80bb3450b2a5",
   "metadata": {},
   "source": [
    "## Q1. Running Elastic\n",
    "Run Elastic Search 8.4.3, and get the cluster information. If you run it on localhost, this is how you do it:\n",
    "\n",
    "What's the version.build_hash value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74eba333-b65e-452f-bbd6-c0c89086ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '12cb7881d643', 'cluster_name': 'docker-cluster', 'cluster_uuid': 's6ehdUFhTYaMEI0J04jzDA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8caf9-70cc-4408-b247-b5db793f6fbd",
   "metadata": {},
   "source": [
    "## Q2. Indexing the data\n",
    "Index the data in the same way as was shown in the course videos. Make the course field a keyword and the rest should be text.\n",
    "\n",
    "Which function do you use for adding your data to elastic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b377ed-55a0-4a54-b203-91438be23af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72bcebb-03b5-4690-8250-b7b7c93f0ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76005822-9f6e-44b9-a7c2-b7578d87f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:23<00:00, 40.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm # progress bar\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c2a9e-a94b-4a69-9bd7-374ef94fa6c4",
   "metadata": {},
   "source": [
    "## Q3. Searching\n",
    "Now let's search in our index.\n",
    "\n",
    "We will execute a query \"How do I execute a command in a running docker container?\".\n",
    "\n",
    "Use only question and text fields and give question a boost of 4, and use \"type\": \"best_fields\".\n",
    "\n",
    "What's the score for the top ranking result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf50910-9ee0-4012-8ebd-a1311497b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I execute a command in a running docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab73f05-8998-4529-9f84-75f16824c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }    \n",
    "    }\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e8bf907-5453-474a-999b-83f581787dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = elastic_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86e6e2c8-696d-4a02-b91f-b7f73465de51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.050095\n"
     ]
    }
   ],
   "source": [
    "hits = search_results.get('hits', {}).get('hits', [])\n",
    "highest_score = max(hit['_score'] for hit in hits)\n",
    "print(highest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f32e84-7f45-48cf-94ce-47e7180a2408",
   "metadata": {},
   "source": [
    "## Q4. Filtering\n",
    "Now let's only limit the questions to machine-learning-zoomcamp.\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2753422-ea65-4245-a60e-d21e2b8e6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92767850-e671-4572-b293-9d6f2ad3d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from my local machine to docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"$ docker exec -it 1e5a1b663052 bash\\nthe input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'\\nFix:\\nwinpty docker exec -it 1e5a1b663052 bash\\nA TTY is a terminal interface that supports escape sequences, moving the cursor around, etc.\\nWinpty is a Windows software package providing an interface similar to a Unix pty-master for communicating with Windows console programs.\\nMore info on terminal, shell, console applications hi and so on:\\nhttps://conemu.github.io/en/TerminalVsShell.html\\n(Marcos MJD)\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'The input device is not a TTY when running docker in interactive mode (Running Docker on Windows in GitBash)',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'Solution\\nThis error was because there was another instance of gunicorn running. So I thought of removing this along with the zoomcamp_test image. However, it didn’t let me remove the orphan container. So I did the following\\nRunning the following commands\\ndocker ps -a <to list all docker containers>\\ndocker images <to list images>\\ndocker stop <container ID>\\ndocker rm <container ID>\\ndocker rmi image\\nI rebuilt the Docker image, and ran it once again; this time it worked correctly and I was able to serve the test script to the endpoint.',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How to fix error after running the Docker run command',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = elastic_search(query)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed7eb8-362d-4e62-b93b-cab838c17908",
   "metadata": {},
   "source": [
    "## Q5. Building a prompt\n",
    "Now we're ready to build a prompt to send to an LLM.\n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (\\n\\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a6f2a-f546-4f5d-841a-fb8c085aa178",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5365b5-9878-4dc9-a9d3-ae3b66101ae6",
   "metadata": {},
   "source": [
    "Now use the context you just created along with the \"How do I execute a command in a running docker container?\" question to construct a prompt using the template below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3ddfeeb-15dd-4c9a-8a5d-a07f482c213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ecb105-dc7d-44a6-90ca-211fbd90bebd",
   "metadata": {},
   "source": [
    "What's the length of the resulting prompt? (use the len function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8cb5961-2a39-480c-95b8-040b76f5f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "for doc in search_results:\n",
    "    context = context + f\"Q: {doc['question']}\\nA: {doc['text']}\\n\\n\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edbdc453-52f6-4d2a-bac0-c02af260d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar AdvaniQ: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar GopinathanQ: The input device is not a TTY when running docker in interactive mode (Running Docker on Windows in GitBash)\n",
      "A: $ docker exec -it 1e5a1b663052 bash\n",
      "the input device is not a TTY.  If you are using mintty, try prefixing the command with 'winpty'\n",
      "Fix:\n",
      "winpty docker exec -it 1e5a1b663052 bash\n",
      "A TTY is a terminal interface that supports escape sequences, moving the cursor around, etc.\n",
      "Winpty is a Windows software package providing an interface similar to a Unix pty-master for communicating with Windows console programs.\n",
      "More info on terminal, shell, console applications hi and so on:\n",
      "https://conemu.github.io/en/TerminalVsShell.html\n",
      "(Marcos MJD)Q: How to fix error after running the Docker run command\n",
      "A: Solution\n",
      "This error was because there was another instance of gunicorn running. So I thought of removing this along with the zoomcamp_test image. However, it didn’t let me remove the orphan container. So I did the following\n",
      "Running the following commands\n",
      "docker ps -a <to list all docker containers>\n",
      "docker images <to list images>\n",
      "docker stop <container ID>\n",
      "docker rm <container ID>\n",
      "docker rmi image\n",
      "I rebuilt the Docker image, and ran it once again; this time it worked correctly and I was able to serve the test script to the endpoint.\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "371fae6b-ba46-4769-9c61-85235ab83ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=query, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9d374f3-6817-456c-ad59-4e2c9b64519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2706"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef78e77-8a4e-4bb7-ae5d-21191c86f111",
   "metadata": {},
   "source": [
    "## Q6. Tokens\n",
    "When we use the OpenAI Platform, we're charged by the number of tokens we send in our prompt and receive in the response.\n",
    "\n",
    "The OpenAI python package uses tiktoken for tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ed2f07e-3ba3-4de4-bfe6-55d38206324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n",
      "Python 3.12.3\n",
      "Name: tiktoken\n",
      "Version: 0.7.0\n",
      "Summary: tiktoken is a fast BPE tokeniser for use with OpenAI's models\n",
      "Home-page: \n",
      "Author: Shantanu Jain\n",
      "Author-email: shantanu@openai.com\n",
      "License: MIT License\n",
      "\n",
      "Copyright (c) 2022 OpenAI, Shantanu Jain\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "\n",
      "Location: /opt/conda/lib/python3.12/site-packages\n",
      "Requires: regex, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python -V\n",
    "!pip show tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2df2a5-a12c-4778-bfbd-b7ace2a30c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/tiktoken.git\n",
      "  Cloning https://github.com/openai/tiktoken.git to /tmp/pip-req-build-xvn6i6_3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/tiktoken.git /tmp/pip-req-build-xvn6i6_3\n",
      "  Resolved https://github.com/openai/tiktoken.git to commit c0ba74c238d18b4824c25f3c27fc8698055b9a76\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex>=2022.1.18 (from tiktoken==0.7.0)\n",
      "  Using cached regex-2024.5.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/envs/myenv/lib/python3.12/site-packages (from tiktoken==0.7.0) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/myenv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/myenv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/myenv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/myenv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.7.0) (2024.6.2)\n",
      "Using cached regex-2024.5.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (788 kB)\n",
      "Building wheels for collected packages: tiktoken\n",
      "  Building wheel for tiktoken (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tiktoken \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[38 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/_educational.py -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/model.py -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/registry.py -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/__init__.py -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/core.py -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/load.py -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/tiktoken_ext\n",
      "  \u001b[31m   \u001b[0m copying tiktoken_ext/openai_public.py -> build/lib.linux-x86_64-cpython-312/tiktoken_ext\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing tiktoken.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to tiktoken.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to tiktoken.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to tiktoken.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'tiktoken.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching 'Makefile'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'tiktoken.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying tiktoken/py.typed -> build/lib.linux-x86_64-cpython-312/tiktoken\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for tiktoken\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build tiktoken\n",
      "\u001b[31mERROR: Could not build wheels for tiktoken, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/tiktoken.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9330c04f-b329-45df-bb7b-d80ed377fd18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiktoken' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtiktoken\u001b[49m\u001b[38;5;241m.\u001b[39mencoding_for_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mencode(prompot)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tiktoken' is not defined"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(prompot)\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
